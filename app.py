
import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="AI QAæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ", layout="centered")
st.title("AI QAãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ãƒ»ãƒãƒ£ãƒƒãƒˆ")

QA_FILE = "QA_ç´¢å¼•ä»˜ãQAé›†.xlsx"
@st.cache_data
def load_qa():
    return pd.read_excel(QA_FILE, sheet_name="å…¨ä»¶ãƒ‡ãƒ¼ã‚¿").dropna(subset=["è³ªå•", "å›ç­”"])

df = load_qa()
corpus = (df["è³ªå•"].fillna("") + " " + df["å›ç­”"].fillna("")).tolist()

if "history" not in st.session_state:
    st.session_state.history = []

user_input = st.text_input("çŸ¥ã‚ŠãŸã„ã“ã¨ãƒ»æ‚©ã¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="user_input")

if user_input:
    tfidf = TfidfVectorizer().fit_transform(corpus + [user_input])
    sims = cosine_similarity(tfidf[-1], tfidf[:-1]).flatten()
    top_idx = sims.argsort()[-5:][::-1]
    best_idx = top_idx[0]
    best_Q = df.iloc[best_idx]["è³ªå•"]
    best_A = df.iloc[best_idx]["å›ç­”"]
    st.session_state.history.append(("ãƒ¦ãƒ¼ã‚¶ãƒ¼", user_input))
    st.session_state.history.append(("AI", f"ãŠã™ã™ã‚Q&Aï¼š\n\n**Q:** {best_Q}\n\n**A:** {best_A}"))
    for role, msg in st.session_state.history:
        if role == "ãƒ¦ãƒ¼ã‚¶ãƒ¼":
            st.markdown(f"ğŸ§‘â€ğŸ’» **ã‚ãªãŸ:** {msg}")
        else:
            st.markdown(f"ğŸ¤– **AI:** {msg}")
    st.markdown("---")
    st.markdown("### ä»–ã«ã‚‚ã“ã‚“ãªQ&AãŒã‚ã‚Šã¾ã™")
    for idx in top_idx[1:]:
        st.markdown(f"- **Q:** {df.iloc[idx]['è³ªå•']}\n    \n**A:** {df.iloc[idx]['å›ç­”']}")
else:
    for role, msg in st.session_state.history:
        if role == "ãƒ¦ãƒ¼ã‚¶ãƒ¼":
            st.markdown(f"ğŸ§‘â€ğŸ’» **ã‚ãªãŸ:** {msg}")
        else:
            st.markdown(f"ğŸ¤– **AI:** {msg}")

st.markdown("---\n\n*ã“ã®ã‚¢ãƒ—ãƒªã¯QAã‚¨ã‚¯ã‚»ãƒ«ã‹ã‚‰è‡ªå‹•æ¤œç´¢ãƒ»æ¨è–¦ã—ã¦ã„ã¾ã™*")
